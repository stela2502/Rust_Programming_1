# Use the Data class to implement a kmeans algorithm

Honestly - nowadays I never start anything without asking ChatGPT first.
So why not use it here, too.


This is my conversation with ChatGPT:

```
Hi Chatgpt. Can you tell me how to code kmeans in Rust if the data is stored in 2d ndarrays  and the rows should be clustered.

Sure, I can help you with that! Here's an implementation of the KMeans algorithm in Rust using the ndarray crate to handle the 2D data:

rust

use ndarray::{Array2, Axis};

fn kmeans(data: &Array2<f64>, k: usize) -> Array2<f64> {
    let n = data.nrows();
    let d = data.ncols();
    let mut centroids = data.slice(s![..k, ..]).to_owned();
    let mut labels = Array2::zeros((n, 1));

    loop {
        let mut new_labels = Array2::zeros((n, 1));
        for i in 0..n {
            let mut min_distance = f64::INFINITY;
            for j in 0..k {
                let distance = (data.slice(s![i, ..]) - centroids.slice(s![j, ..])).norm();
                if distance < min_distance {
                    min_distance = distance;
                    new_labels[[i, 0]] = j as f64;
                }
            }
        }
        if new_labels == labels {
            break;
        }
        labels.assign(&new_labels);
        for j in 0..k {
            let mask = labels.iter().enumerate().filter(|(_, &l)| l == j as f64)
                .map(|(i, _)| i).collect::<Vec<_>>();
            let cluster_data = data.select(Axis(0), &mask);
            if !cluster_data.is_empty() {
                centroids.slice_mut(s![j, ..]).assign(&cluster_data.mean_axis(Axis(0)).unwrap());
            }
        }
    }
    labels
}

This implementation takes as input an Array2<f64> representing the data, and an integer k representing the number of clusters to find. It returns an Array2<f64> of the same shape as the input data, containing the cluster labels for each row.

The algorithm works as follows:

    Initialize centroids to k randomly chosen rows from the input data.
    Loop until convergence:
    a. Assign each row to the cluster with the closest centroid.
    b. Update the centroid of each cluster to be the mean of its assigned rows.
    c. If the cluster assignments haven't changed, exit the loop.
    Return the cluster labels for each row.

The implementation should be fairly self-explanatory, but I'll provide some additional details:

    We use the norm() method to compute the Euclidean distance between a row of data and a centroid.
    The slice() method is used to extract subsets of the data and centroids arrays.
    The select() method is used to extract the rows of data belonging to a given cluster.
    The mean_axis() method is used to compute the mean of the rows belonging to a given cluster.

Hope that helps! Let me know if you have any questions.
````

## Implement the kmeans algorithm using the AI output?

Sure - why not. Let's recapitulate what the kmers algorithm should do and check if we find the respective lines in the code.

The data should already be in memory and it should be a ndarray. Here it is obviously called "data". But I would not like to have an Array2<f64> back.
This function should rather return the cluster identities for each row as a Vec<usize>. Keep that in mind for later.

The next step in the kmeans algorithm is to select a random set of initial 'centromers'. This step is totally missing in the AI function.
To select a random set of starting rows we need a random number generator. In Rust this works like that:

```
use rand::Rng;
let mut rng = rand::thread_rng();
rng.gen_range(0..100); // gives a random number in this range.
```

Next we loop until convergence is reached. That is fine. 
BUT we do not want the program to end in an endless loop. 
Add another variable called max_it:usize and use this in a 'for' loop.


# Let's walk through:

Change the data type (to the type we have in our read_data), the return value and add a way to select the initial random set of centroids.


```
use ndarray::ArrayBase;
use rand::Rng;


fn kmeans(data: &ArrayBase<ndarray::OwnedRepr<f64>, Dim<[usize; 2]>>, k: usize) -> Vec<usize> {
    let n = data.nrows();
    let d = data.ncols();
    let mut rng = rand::thread_rng();

    let mut centroids = Array::zeros((k, data.len_of(Axis(1))));
    for i in  0..k{
        let sample_idx = rng.gen_range(0..n);
        centroids.row_mut(i).assign(&self.data.row(sample_idx));
    }
    let mut labels = Vec<usize>::with_capacity(n);

    .
    .
    .
}
```

You see the creation of the initial lables changed quite a bit from the AI generated ``let mut centroids = data.slice(s![..k, ..]).to_owned();``. We now get exactly k random rows of the data.
I got the way to copy the data using ChatGPT - again ;-)


## Should we have more functions?

Now we would calculate the closest centroid for each row of the data.
We will need this functionality also in the loop. As we use the same functionality more than once I would implement a function to do that.
This function should compare the centroids to every row of the data.


```
use ndarray::ArrayBase;
use rand::Rng;


fn asign_labels(data: &ArrayBase<ndarray::OwnedRepr<f64>, Dim<[usize; 2]>>, centroids: &ArrayBase<ndarray::OwnedRepr<f64>, Dim<[usize; 2]>> ) -> Vec<usize> {
    let n = data.nrows();
    let mut labels = Vec<usize>::with_capacity( n );
    
    for id in 0..n{
        let mut min_distance = f64::INFINITY;
        for j in 0..k {
            let distance = (data.slice(s![i, ..]) - centroids.slice(s![j, ..])).norm();
            if distance < min_distance {
                min_distance = distance;
                labels[i] = j;
            }
        }
    }
    labels
}

fn kmeans(data: &ArrayBase<ndarray::OwnedRepr<f64>, Dim<[usize; 2]>>, k: usize) -> Vec<usize> {
    let n = data.nrows();
    let d = data.ncols();
    let mut rng = rand::thread_rng();

    let mut centroids = Array::zeros((k, data.len_of(Axis(1))));
    for i in  0..k{
        let sample_idx = rng.gen_range(0..n);
        centroids.row_mut(i).assign(&self.data.row(sample_idx));
    }
    let mut labels = asign_labels( data, centroids );

    .
    .
    .
}

```

The asign_labels function is mainly a straight copy from the initial AI result.

## Add a function to calculate the new centroids

The next time we get the centroids will be more complicated.
I like functions as one can also create specific tests for each function.
AND THAT IS SOMETHING WE SHOULD REALLY DO!

But first the calculate_centroids function:

```
use ndarray::ArrayBase;
use rand::Rng;


fn asign_labels(data: &ArrayBase<ndarray::OwnedRepr<f64>, Dim<[usize; 2]>>, centroids: &ArrayBase<ndarray::OwnedRepr<f64>, Dim<[usize; 2]>> ) -> Vec<usize> {
    let n = data.nrows();
    let mut labels = Vec<usize>::with_capacity( n );
    
    for id in 0..n{
        let mut min_distance = f64::INFINITY;
        for j in 0..k {
            let distance = (data.slice(s![i, ..]) - centroids.slice(s![j, ..])).norm();
            if distance < min_distance {
                min_distance = distance;
                labels[[i, 0]] = j;
            }
        }
    }
    labels
}

fn calculate_centroids( data: &ArrayBase<ndarray::OwnedRepr<f64>, Dim<[usize; 2]>>, labels:Vec<usize>, 
            k:usize, &mut centroids: &ArrayBase<ndarray::OwnedRepr<f64>, Dim<[usize; 2]>> ) {

    for j in 0..k {
        let mask = labels.iter().enumerate().filter(|(_, &l)| l == j )
            .map(|(i, _)| i).collect::<Vec<_>>();
        let cluster_data = data.select(Axis(0), &mask);
        if !cluster_data.is_empty() {
            centroids.slice_mut(s![j, ..]).assign(&cluster_data.mean_axis(Axis(0)).unwrap());
        }
    } 
}

fn kmeans(data: &ArrayBase<ndarray::OwnedRepr<f64>, Dim<[usize; 2]>>, k: usize, max_it:usize) -> Vec<usize> {
    let n = data.nrows();
    let d = data.ncols();
    let mut rng = rand::thread_rng();

    let mut centroids = Array::zeros((k, data.len_of(Axis(1))));
    for i in  0..k{
        let sample_idx = rng.gen_range(0..n);
        centroids.row_mut(i).assign(&self.data.row(sample_idx));
    }
    let mut labels = asign_labels( data, centroids );
    let mut new_labels:Vec<usize>;

    for it in 0..max_it{
        calculate_centroids( data, labels, k, centroids );
        new_labels = asign_labels( data, centroids );
        if new_labels == labels{
            print("converged after {it} itherations");
            break;
        }
        labels = new_labels;
    }
    labels
}

```

In the calculate centroids I now also give the centroids to the function. This way we do not need to create a temporary variable holding the centroids, but change the values in the variable of the kmeans function. That is quite slick and we should probably also have done that in the asigne_lables function. Would it make sense there, too?


# And the TESTING!


As we now have so many nice functions that could be tested - lets add some tests:

To be able to test this we now neeed some data in this. :-(
Let's combine the kmeans functionality with the Data object we had as an example before.

Copy the read_data folder and name it kmeans.
Now you need to change the Cargo.toml: read_data to kmeans.

You could compile it and check if it is still working.

Add the kmeans functionality to the Data class or to the main.rs script.
This will take some time - I will help you, but there will be no help in this document.

We go on with the testing here:


```

#[cfg(test)]
mod tests {

    use crate::data::Data;
    use ndarray::Axis;
    use ndarray::ArrayBase;


    #[test]
    fn check_asign_labels() {
        let mut data = Data::read_file( &"testData/CellexalVR_TestData_tsne.csv".to_string(), ',' );
        let mut centroids = data.slice(s![..10, ..]).to_owned();
        let mut labels Vec<usize>::with_capacity( data.nrows() );
        data.calculate_centroids( centroids, labels )
    }


    #[test]
    fn check_kmeans() {

        let mut data = Data::read_file( &"testData/CellexalVR_TestData_tsne.csv".to_string(), ',' );
        data.scale();
        let kmeans = data.kmeans( 15, 15000 );
        assert_eq!( kmeans.len(), data.data.len_of(Axis(0)) );

        let exp:Vec<usize> = vec![0; data.data.len_of(Axis(0)) ];
        assert!( kmeans != exp, "the kmeans values are not zero" );
    }

    #[test]
    fn check_calculate_centroids() {
        // implement that if you like - I do not want to :-D
    }

}

```

Add these tests BEFORE you implement the functions. This way you have a simple test to check if it does work ;-)
